# Install and Configure Archiver

The SAPS Archiver component is responsible to collect data and metadata generated by tasks whose processing have either finished or failed. To this end, the Archive interacts with the SAPS Service Catalog, temporary and permanent storage pools.
  
## Dependencies

In an apt-based Linux distro, type the below commands to install the Archiver dependencies.

```bash
sudo apt-get update
sudo apt-get -y install openjdk-8-jdk
sudo apt-get -y install maven
sudo apt-get -y install git
sudo apt -y install python-swiftclient
sudo apt-get install -y nfs-kernel-server
```

In addition to above Linux packages, download the own ```saps-engine``` repository (which holds the Archive code). To fetch and compile the source code of it, follow the below steps:

```
git clone https://github.com/ufcg-lsd/saps-engine
cd saps-engine
git checkout develop
mvn install -Dmaven.test.skip=true
```

## Configure

### Temporary Storage


The first part of SAPS Archiver configuration deals with the setup of the ```NFS server temporary storage```. Before starting the NFS daemon, please choose an directory, ```$nfs_server_dir_path```, in your machine local file system. The NFS daemon will hold the exported files within this directory. Below commands setup the NFS server:

```
mkdir -p $nfs_server_dir_path
echo "$nfs_server_dir_path *(rw,insecure,no_subtree_check,async,no_root_squash)" >> /etc/exports
sudo service nfs-kernel-server restart
```

To check, list the directories mounted with nfs using the command below and check if the directory you just created appears.
```
showmount -e localhost
```

### Configuration File


The second part of the Archiver configuration (made via the ```archiver.conf``` file) customize this component to interact with other componenents, including the SAPS Catalog, the temporary and permanent storage pools.

```
##### Archiver properties #####
# Time sleep in seconds to run the archiving routine (default = 300)
saps_execution_period_archiver=300
# Time sleep in seconds to run the failed task cleanup routine (default = 30)
saps_execution_period_garbage_collector=30
# Debug mode (default = true) 
# When executing in debug mode, the output generated by failed tasks are also kept in the permanent storage
saps_execution_debug_mode=true

##### Catalog #####
# URL prefix (default = jdbc:postgresql://)
datastore_url_prefix=jdbc:postgresql://
datastore_ip=$catalog_ip_address
# Port (default = 5432)
datastore_port=5432
datastore_name=$catalog_db_name
# Driver (default = org.postgresql.Driver)
datastore_driver=org.postgresql.Driver
datastore_username=$catalog_user
datastore_password=$catalog_passwd

##### Temporary Storage (NFS) #####
# Path mounted by the client
saps_temp_storage_path=$nfs_server_dir_path

##### Permanent storage (Swift) #####
saps_permanent_storage_type=swift
# Directory prefix for to archive failed tasks case debug mode is true (default = trash)
permanent_storage_debug_tasks_dir=trash
# Directory prefix for to archive success tasks (default = archiver)
permanent_storage_tasks_dir=archiver
# Container name
swift_container_name=$swift_container_name
# Username
swift_username=$openstack_username
# Password
swift_password=$openstack_password
# Identity URL + version (e.g. https://<domain>:5000/v1)
swift_auth_url=$openstack_identity_url

swift_object_store_key=

##### Fogbow Keystone #####
# Project ID
fogbow.keystonev3.project.id=$openstack_project_id
# User ID
fogbow.keystonev3.user.id=$openstack_user_id
# Password
fogbow.keystonev3.password=$openstack_password
# Identity URL (e.g. https://<domain>:5000)
fogbow.keystonev3.auth.url=$openstack_identity_url
# Object Store URL (e.g. https://<domain>:8080/swift/v1)
fogbow.keystonev3.swift.url=$openstack_object_store_url
```

## Run
Once the configuration file is customized, below command are used to start and stop the Archiver component.

```
# Start command
bash bin/start-archiver
```

```
# Stop command
bash bin/stop-archiver
```
